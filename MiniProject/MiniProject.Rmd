---
title: "CSC 587 MiniProjecty"
author: "Daniel R. Getty"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: 
    css: "style.css"
    includes:
      in_header: logo.html
---

```{r rsetup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = TRUE, results='asis')
```


```{python psetup, include=FALSE}
import os
import pandas as pd
import numpy as np

# print working directory
os.getcwd()
filename = 'labeledPackets50.csv'

# make a array, li, to hold both initial data frames from the CSV files
li = []
li.append(pd.read_csv(filename))
data = pd.concat(li, axis=0,ignore_index=True)
```

```{python preprocess Data}
# preprocess the data
#import ipaddress

# loop through all indexes to preprocessdata
for index in range(len(data)):
  # clean up responsetimetimemedian and responsetimetimeskewfrommedian NaN values
  if np.isnan(data.loc[index,'ResponseTimeTimeMedian']):
     data.at[index,'ResponseTimeTimeMedian'] = 0
  if np.isnan(data.loc[index,'ResponseTimeTimeSkewFromMedian']):
     data.at[index,'ResponseTimeTimeSkewFromMedian'] = 0

# drop unwanted columns
data = data.drop(['TimeStamp','SourceIP','DestinationIP','SourcePort','DestinationPort'],axis=1)
# verify; check for NaN left
for col in data.columns:
      NaNsum = data.loc[:,col].isna().sum()
      if NaNsum > 0:
        print("Col: %s NaN: %d" % (col,NaNsum))

# for col in data.columns:
#       NaNsum = data.loc[:,col].isna().sum()
#       if NaNsum > 0:
#         print("Col: %s NaN: %d" % (col,NaNsum))
#               
row_count = data.shape[0]
print("Row Count: %d" % row_count)
print(data.head())
```

```{python Train Test SPlit}
# get the data ready to be put into the decision tree/Naive Bayes/SVM
from sklearn.model_selection import train_test_split
from sklearn import tree

# training data
cdata = data.drop('Label', axis=1)
labels = data['Label']

# # preprocess
# from sklearn.preprocessing import OneHotEncoder
# from sklearn.compose import ColumnTransformer
# from sklearn.preprocessing import StandardScaler


# split things up 80%/20%
cdata_train, cdata_test, labels_train, labels_test = train_test_split(cdata,labels, test_size=0.2, random_state=1)

print("Training Data Shape: %s" % str(cdata_train.shape))
print("Testing Data Shape: %s" % str(cdata_test.shape))
print("Training Labels Shape: %s" % str(labels_train.shape))
print("Testing Labels Shape: %s" % str(labels_test.shape))

# make the decision tree - unlimited depth
cls = tree.DecisionTreeClassifier()
cls.fit(cdata_train, labels_train)

# make a second decision tree - max depth 10
clsd10 = tree.DecisionTreeClassifier(max_depth=10)
clsd10.fit(cdata_train, labels_train)

```

```{python Decision Tree}
from sklearn.tree import export_graphviz
from io import StringIO
from IPython.display import Image
import pydotplus

# make the first unlimited depth tree
dot_data = StringIO()
export_graphviz(cls, out_file=dot_data, filled=True, rounded=True, special_characters=True, feature_names = cdata.columns, class_names=['DoH','nonDoH'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
Image(graph.create_png())
```
